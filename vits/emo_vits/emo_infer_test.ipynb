{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import commons\n",
    "import utils\n",
    "from emo_data_utils import (\n",
    "    TextAudioLoader,\n",
    "    TextAudioCollate,\n",
    "    TextAudioSpeakerLoader,\n",
    "    TextAudioSpeakerCollate,\n",
    ")\n",
    "from emo_models import SynthesizerTrn\n",
    "from text.symbols import symbols\n",
    "from text import text_to_sequence\n",
    "\n",
    "\n",
    "def get_text(text, hps):\n",
    "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm\n",
    "\n",
    "\n",
    "def load_data_from_json(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        test_text_sem_dic = json.load(file)\n",
    "    for key in test_text_sem_dic:\n",
    "        test_text_sem_dic[key] = torch.tensor(test_text_sem_dic[key])\n",
    "    return test_text_sem_dic\n",
    "\n",
    "\n",
    "def ensure_directory_exists(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LJ Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose pretrained model and the trained step\n",
    "model = \"ljs_emo_add_ave\"\n",
    "model = \"ljs_emo_add_last\"\n",
    "model = \"ljs_emo_add_pca\"\n",
    "model = \"ljs_emo_add_eis_word\"\n",
    "model = \"ljs_emo_add_eis_sentence\"\n",
    "model = \"ljs_emo_add_bert_cls\"\n",
    "model = \"onehour_ljs_emo_add_ave\"\n",
    "model = \"onehour_ljs_emo_add_last\"\n",
    "model = \"onehour_ljs_emo_add_pca\"\n",
    "model = \"onehour_ljs_emo_add_eis_word\"\n",
    "model = \"onehour_ljs_emo_add_eis_sentence\"\n",
    "model = \"onehour_ljs_emo_add_bert_cls\"\n",
    "model = \"emovdb_emo_add_ave_pretrained16\"\n",
    "model = \"emovdb_emo_add_last_pretrained16\"\n",
    "model = \"emovdb_emo_add_pca_pretrained16\"\n",
    "model = \"emovdb_emo_add_eis_word_pretrained16\"\n",
    "model = \"emovdb_emo_add_eis_sentence_pretrained16\"\n",
    "model = \"emovdb_emo_add_bert_cls_pretrained16\"\n",
    "\n",
    "# step = 'G_50000'\n",
    "# step = \"G_100000\"\n",
    "step = \"G_150000\"\n",
    "\n",
    "\n",
    "common_dir = \"vits/\"\n",
    "log_dir = f\"{common_dir}emo_vits/logs/\"\n",
    "save_dir = f\"{log_dir}{model}/{step}/source_model_test_wav\"\n",
    "ensure_directory_exists(save_dir)\n",
    "hps = utils.get_hparams_from_file(f\"{log_dir}{model}/config.json\")\n",
    "sem_embedding = hps.data.sem_embedding\n",
    "print(f\"sem_embedding: {sem_embedding}\")\n",
    "\n",
    "# Dictionary to map the model to its corresponding test_text_sem_dic_file\n",
    "model_to_test_text_sem_dic = {\n",
    "    \"ljs_emo_add_ave\": \"ljs_text_sem_ave_5120.json\",\n",
    "    \"ljs_emo_add_last\": \"ljs_text_sem_last_5120.json\",\n",
    "    \"ljs_emo_add_pca\": \"ljs_text_sem_pca_5120.json\",\n",
    "    \"ljs_emo_add_eis_word\": \"ljs_text_sem_eis_word_5120.json\",\n",
    "    \"ljs_emo_add_eis_sentence\": \"ljs_text_sem_eis_sentence_5120.json\",\n",
    "    \"ljs_emo_add_bert_cls\": \"ljs_text_bert_cls_768.json\",\n",
    "    \"onehour_ljs_emo_add_ave\": \"ljs_text_sem_ave_5120.json\",\n",
    "    \"onehour_ljs_emo_add_last\": \"ljs_text_sem_last_5120.json\",\n",
    "    \"onehour_ljs_emo_add_pca\": \"ljs_text_sem_pca_5120.json\",\n",
    "    \"onehour_ljs_emo_add_eis_word\": \"ljs_text_sem_eis_word_5120.json\",\n",
    "    \"onehour_ljs_emo_add_eis_sentence\": \"ljs_text_sem_eis_sentence_5120.json\",\n",
    "    \"onehour_ljs_emo_add_bert_cls\": \"ljs_text_bert_cls_768.json\",\n",
    "    \"librif_emo_add_ave\": \"librif_text_sem_ave_5120.json\",\n",
    "    \"librif_emo_add_last\": \"librif_text_sem_last_5120.json\",\n",
    "    \"librif_emo_add_pca\": \"librif_text_sem_pca_5120.json\",\n",
    "    \"librif_emo_add_eis_word\": \"librif_text_sem_eis_word_5120.json\",\n",
    "    \"librif_emo_add_eis_sentence\": \"librif_text_sem_eis_sentence_5120.json\",\n",
    "    \"librif_emo_add_bert_cls\": \"librif_text_bert_cls_768.json\",\n",
    "    \"emovdb_emo_add_ave\": \"emovdb_text_sem_ave_5120.json\",\n",
    "    \"emovdb_emo_add_last\": \"emovdb_text_sem_last_5120.json\",\n",
    "    \"emovdb_emo_add_pca\": \"emovdb_text_sem_pca_5120.json\",\n",
    "    \"emovdb_emo_add_eis_word\": \"emovdb_text_sem_eis_word_5120.json\",\n",
    "    \"emovdb_emo_add_eis_sentence\": \"emovdb_text_sem_eis_sentence_5120.json\",\n",
    "    \"emovdb_emo_add_bert_cls\": \"emovdb_text_bert_cls_768.json\",\n",
    "    \"emovdb_emo_add_ave_pretrained16\": \"emovdb_text_sem_ave_5120.json\",\n",
    "    \"emovdb_emo_add_last_pretrained16\": \"emovdb_text_sem_last_5120.json\",\n",
    "    \"emovdb_emo_add_pca_pretrained16\": \"emovdb_text_sem_pca_5120.json\",\n",
    "    \"emovdb_emo_add_eis_word_pretrained16\": \"emovdb_text_sem_eis_word_5120.json\",\n",
    "    \"emovdb_emo_add_eis_sentence_pretrained16\": \"emovdb_text_sem_eis_sentence_5120.json\",\n",
    "    \"emovdb_emo_add_bert_cls_pretrained16\": \"emovdb_text_bert_cls_768.json\",\n",
    "}\n",
    "# Get the corresponding test_text_sem_dic_file for the chosen model\n",
    "test_text_sem_dic_file = model_to_test_text_sem_dic[model]\n",
    "test_text_sem_dic = load_data_from_json(\n",
    "    f\"{common_dir}filelists/{test_text_sem_dic_file}\"\n",
    ")\n",
    "# print(test_text_sem_dic['The fourth and fifth days passed without any developments.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_g = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    **hps.model,\n",
    ").cuda()\n",
    "_ = net_g.eval()\n",
    "\n",
    "_ = utils.load_checkpoint(f\"{log_dir}{model}/{step}.pth\", net_g, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(test_text_sem_dic.keys())\n",
    "range_limit = len(keys)\n",
    "range_limit = min(range_limit, len(keys))\n",
    "print(f\"range_limit: {range_limit}\")\n",
    "m = 5\n",
    "\n",
    "for i in range(range_limit):\n",
    "    key = keys[i]  # key is string\n",
    "    s = get_text(key, hps)  # assign key to s\n",
    "    print(key)\n",
    "    with torch.no_grad():\n",
    "        x_tst = s.cuda().unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([s.size(0)]).cuda()\n",
    "        emb_sem = test_text_sem_dic[\n",
    "            key\n",
    "        ].cuda()  # get corresponding tensor from dictionary\n",
    "        print(f\"x_tst: {x_tst.shape}\")\n",
    "        print(f\"x_tst_lengths: {x_tst_lengths}\")\n",
    "        print(f\"emb_sem: {emb_sem.shape}\")\n",
    "        audio = (\n",
    "            net_g.infer(\n",
    "                x_tst,\n",
    "                x_tst_lengths,\n",
    "                noise_scale=0.667,\n",
    "                noise_scale_w=0.8,\n",
    "                length_scale=1,\n",
    "                emb_sem=emb_sem,\n",
    "            )[0][0, 0]\n",
    "            .data.cpu()\n",
    "            .float()\n",
    "            .numpy()\n",
    "        )\n",
    "    if i < m:\n",
    "        ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))\n",
    "    write(f\"{save_dir}/output_emo_{i}.wav\", hps.data.sampling_rate, audio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
